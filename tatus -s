[1mdiff --git a/README.md b/README.md[m
[1mindex 243ee7c..816ecbe 100644[m
[1m--- a/README.md[m
[1m+++ b/README.md[m
[36m@@ -1,61 +1,392 @@[m
[31m-# SOLID κΈ°λ° LangChain + Ollama + Streamlit μ±—λ΄‡[m
[32m+[m[32m# π¤– SOLID κΈ°λ° Multi-LLM μ±—λ΄‡ ν”„λ μ„μ›ν¬[m
 [m
[31m-## κ°μ”[m
[31m-- μ΄ ν”„λ΅μ νΈλ” SOLID μ›μΉ™μ„ μ² μ €ν μ¤€μν•μ—¬ μ„¤κ³„λ λ€ν™”ν• μ±—λ΄‡ μμ μ…λ‹λ‹¤.[m
[31m-- LangChain, Ollama(λ΅μ»¬ LLM), Streamlitμ„ ν™μ©ν•μ—¬ ν™•μ¥μ„±κ³Ό μ μ§€λ³΄μμ„±μ΄ λ›°μ–΄λ‚ κµ¬μ΅°λ¥Ό μ κ³µν•©λ‹λ‹¤.[m
[32m+[m[32m[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)[m
[32m+[m[32m[![LangChain](https://img.shields.io/badge/LangChain-Latest-green.svg)](https://www.langchain.com/)[m
[32m+[m[32m[![SOLID](https://img.shields.io/badge/Design-SOLID-orange.svg)](https://en.wikipedia.org/wiki/SOLID)[m
[32m+[m[32m[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)[m
 [m
[31m-## μ£Όμ” νΉμ§•[m
[31m-- **SOLID μ›μΉ™ μ¤€μ**: λ‹¨μΌ μ±…μ„, κ°λ°©/νμ‡„, λ¦¬μ¤μ½”ν”„ μΉν™, μΈν„°νμ΄μ¤ λ¶„λ¦¬, μμ΅΄ μ—­μ „ μ›μΉ™ μ μ©[m
[31m-- **λ¨λ“ν™”**: LLM, Agent, UIλ¥Ό κ°κ° λ¶„λ¦¬ν•μ—¬ κ΄€λ¦¬[m
[31m-- **ν™•μ¥μ„±**: μƒλ΅μ΄ LLM, Tool, Agent, UIλ¥Ό μ‰½κ² μ¶”κ°€/κµμ²΄ κ°€λ¥[m
[31m-- **Streamlit UI**: μ›Ή λΈλΌμ°μ €μ—μ„ λ°”λ΅ λ€ν™” κ°€λ¥[m
[32m+[m[32m## π“‹ κ°μ”[m
[32m+[m
[32m+[m[32m**SOLID μ›μΉ™**μ„ μ² μ €ν μ¤€μν•μ—¬ μ„¤κ³„λ ν™•μ¥ κ°€λ¥ν• λ€ν™”ν• μ±—λ΄‡ ν”„λ μ„μ›ν¬μ…λ‹λ‹¤.[m
[32m+[m
[32m+[m[32mν•µμ‹¬ κΈ°λ¥:[m
[32m+[m[32m- π”„ **λ‹¤μ¤‘ LLM μ§€μ›**: Ollama(λ΅μ»¬) / OpenAI(ν΄λΌμ°λ“) κ°„ λ™μ  μ „ν™[m
[32m+[m[32m- π­ **Factory ν¨ν„΄**: λ°νƒ€μ„μ— LLM μ κ³µμ μ„ νƒ[m
[32m+[m[32m- π” **MCP ν”„λ΅ν† μ½**: Model Context Protocol κΈ°λ° ν΄ μ„λ²„[m
[32m+[m[32m- π§© **λ¨λ“ν• μ•„ν‚¤ν…μ²**: λμ¨ν• κ²°ν•©(Loose Coupling)κ³Ό λ†’μ€ μ‘μ§‘λ„(High Cohesion)[m
[32m+[m[32m- π¨ **Streamlit UI**: μ›Ή κΈ°λ° μΈν„°λ™ν‹°λΈ μΈν„°νμ΄μ¤[m
[32m+[m
[32m+[m[32m## β¨ μ£Όμ” νΉμ§•[m
[32m+[m
[32m+[m[32m### SOLID μ›μΉ™ μ™„λ²½ μ μ©[m
[32m+[m[32m| μ›μΉ™ | μ μ© μ‚¬λ΅€ |[m
[32m+[m[32m|------|-----------|[m
[32m+[m[32m| **S**ingle Responsibility | κ° ν΄λμ¤λ” ν•λ‚μ μ±…μ„λ§ (LLM, Agent, UI λ¶„λ¦¬) |[m
[32m+[m[32m| **O**pen/Closed | Factoryλ¥Ό ν†µν• ν™•μ¥ (μƒ LLM μ¶”κ°€ μ‹ κΈ°μ΅΄ μ½”λ“ μμ • λ¶ν•„μ”) |[m
[32m+[m[32m| **L**iskov Substitution | λ¨λ“  LLMμ€ BaseLLMμΌλ΅ μΉν™ κ°€λ¥ |[m
[32m+[m[32m| **I**nterface Segregation | ν΄λΌμ΄μ–ΈνΈλ” ν•„μ”ν• μΈν„°νμ΄μ¤λ§ μμ΅΄ |[m
[32m+[m[32m| **D**ependency Inversion | κµ¬μ²΄ ν΄λμ¤κ°€ μ•„λ‹ μ¶”μƒν™”(BaseLLM)μ— μμ΅΄ |[m
[32m+[m
[32m+[m[32m### μ§€μ› LLM μ κ³µμ[m
[32m+[m[32m- β… **Ollama**: λ΅μ»¬ LLM (λ¬΄λ£, ν”„λΌμ΄λ²„μ‹ λ³΄μ¥)[m
[32m+[m[32m  - llama2, llama3, gemma, mistral λ“±[m
[32m+[m[32m- β… **OpenAI**: ν΄λΌμ°λ“ LLM (API ν‚¤ ν•„μ”)[m
[32m+[m[32m  - gpt-4, gpt-3.5-turbo λ“±[m
[32m+[m[32m- π” **ν™•μ¥ κ°€λ¥**: Anthropic Claude, Google Gemini λ“± μ¶”κ°€ κ°€λ¥[m
 [m
 ## ν΄λ”/νμΌ κµ¬μ΅°[m
 ```[m
 project/[m
 β”β”€ llm/[m
[31m-β”‚   β”β”€ base.py           # LLM μ¶”μƒν™”(ABC)[m
[31m-β”‚   β””β”€ ollama.py         # Ollama LLM κµ¬ν„[m
[32m+[m[32mβ”‚   β”β”€ __init__.py         # λ¨λ“ μΈν„°νμ΄μ¤[m
[32m+[m[32mβ”‚   β”β”€ base_llm.py         # LLM μ¶”μƒ κΈ°λ° ν΄λμ¤ (ABC)[m
[32m+[m[32mβ”‚   β”β”€ ollama.py           # Ollama LLM κµ¬ν„[m
[32m+[m[32mβ”‚   β”β”€ openai_llm.py       # OpenAI LLM κµ¬ν„[m
[32m+[m[32mβ”‚   β”β”€ factory.py          # LLM Factory ν¨ν„΄[m
[32m+[m[32mβ”‚   β””β”€ example_usage.py    # μ‚¬μ© μμ [m
 β”β”€ agent/[m
[31m-β”‚   β””β”€ simple_agent.py   # λ‹¨μ μ—μ΄μ „νΈ[m
[32m+[m[32mβ”‚   β””β”€ memory_agent.py     # λ©”λ¨λ¦¬ κΈ°λ° μ—μ΄μ „νΈ[m
 β”β”€ ui/[m
[31m-β”‚   β””β”€ streamlit_ui.py   # Streamlit UI[m
[31m-β”β”€ main.py               # μ „μ²΄ μ΅°λ¦½ λ° μ‹¤ν–‰ μ—”νΈλ¦¬ν¬μΈνΈ[m
[31m-β”β”€ requirements.txt      # μμ΅΄μ„± λ©λ΅[m
[31m-β”β”€ RULES.md              # ν”„λ΅μ νΈ κ°λ° κ·μΉ™(SOLID λ“±)[m
[31m-β””β”€ README.md             # (μ΄ λ¬Έμ„)[m
[31m-```[m
[31m-[m
[31m-## μ‹¤ν–‰ λ°©λ²•[m
[31m-1. **Ollama μ„λ²„ μ‹¤ν–‰**[m
[31m-   ```bash[m
[31m-   ollama serve[m
[31m-   ```[m
[31m-2. **ν•„μ”μ‹ λ¨λΈ λ‹¤μ΄λ΅λ“ λ° λ΅λ“**[m
[31m-   ```bash[m
[31m-   ollama run gemma3n:e4b[m
[31m-   ```[m
[31m-3. **ν•„μ” ν¨ν‚¤μ§€ μ„¤μΉ**[m
[31m-   ```bash[m
[31m-   pip install -r requirements.txt[m
[31m-   ```[m
[31m-4. **Streamlit UI μ‹¤ν–‰**[m
[31m-   ```bash[m
[31m-   streamlit run main.py[m
[31m-   ```[m
[31m-5. **μ›Ή λΈλΌμ°μ €μ—μ„ μ ‘μ†**[m
[31m-   - http://localhost:8501[m
[31m-[m
[31m-## κ°λ° κ·μΉ™[m
[31m-- μμ„Έν• λ‚΄μ©μ€ RULES.md μ°Έκ³ [m
[32m+[m[32mβ”‚   β””β”€ streamlit_ui.py     # Streamlit UI[m
[32m+[m[32mβ”β”€ mcp-server/[m
[32m+[m[32mβ”‚   β”β”€ server/[m
[32m+[m[32mβ”‚   β”‚   β””β”€ main.py         # MCP μ„λ²„ (pay ν΄)[m
[32m+[m[32mβ”‚   β”β”€ client/[m
[32m+[m[32mβ”‚   β”‚   β””β”€ main.py         # MCP ν΄λΌμ΄μ–ΈνΈ[m
[32m+[m[32mβ”‚   β””β”€ README.md           # MCP μ‹¤ν–‰ κ°€μ΄λ“[m
[32m+[m[32mβ”β”€ main.py                 # μ „μ²΄ μ΅°λ¦½ λ° μ‹¤ν–‰ μ—”νΈλ¦¬ν¬μΈνΈ[m
[32m+[m[32mβ”β”€ requirements.txt        # μμ΅΄μ„± λ©λ΅[m
[32m+[m[32mβ”β”€ RULES.md                # ν”„λ΅μ νΈ κ°λ° κ·μΉ™(SOLID λ“±)[m
[32m+[m[32mβ””β”€ README.md               # (μ΄ λ¬Έμ„)[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## π€ λΉ λ¥Έ μ‹μ‘[m
[32m+[m
[32m+[m[32m### 1οΈβƒ£ ν•„μ ν¨ν‚¤μ§€ μ„¤μΉ[m
[32m+[m[32m```bash[m
[32m+[m[32mpip install -r requirements.txt[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### 2οΈβƒ£ LLM μ κ³µμ μ„ νƒ λ° μ‹¤ν–‰[m
[32m+[m
[32m+[m[32m<details open>[m
[32m+[m[32m<summary><b>Option A: Ollama μ‚¬μ© (λ΅μ»¬ LLM, κ¶μ¥)</b></summary>[m
[32m+[m
[32m+[m[32m**μ¥μ **: λ¬΄λ£, λΉ λ¦„, ν”„λΌμ΄λ²„μ‹ λ³΄μ¥[m
[32m+[m
[32m+[m[32m#### μ„¤μΉ (μµμ΄ 1ν)[m
[32m+[m[32m```bash[m
[32m+[m[32m# Ollama μ„¤μΉ: https://ollama.ai/download[m
[32m+[m
[32m+[m[32m# λ¨λΈ λ‹¤μ΄λ΅λ“[m
[32m+[m[32mollama pull gemma3n:e4b[m
[32m+[m[32m# λλ”[m
[32m+[m[32mollama pull llama2[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### μ‹¤ν–‰[m
[32m+[m[32m```bash[m
[32m+[m[32m# ν„°λ―Έλ„ 1: Ollama μ„λ²„ μ‹¤ν–‰[m
[32m+[m[32mollama serve[m
[32m+[m
[32m+[m[32m# ν„°λ―Έλ„ 2: Streamlit UI μ‹¤ν–‰[m
[32m+[m[32mstreamlit run main.py[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m</details>[m
[32m+[m
[32m+[m[32m<details>[m
[32m+[m[32m<summary><b>Option B: OpenAI μ‚¬μ© (ν΄λΌμ°λ“ LLM)</b></summary>[m
[32m+[m
[32m+[m[32m**μ¥μ **: κ°•λ ¥ν• μ„±λ¥, μ„¤μΉ λ¶ν•„μ”[m[41m  [m
[32m+[m[32m**λ‹¨μ **: API ν‚¤ ν•„μ”, λΉ„μ© λ°μƒ[m
[32m+[m
[32m+[m[32m#### Linux / macOS[m
[32m+[m[32m```bash[m
[32m+[m[32mexport OPENAI_API_KEY='sk-your-api-key-here'[m
[32m+[m[32mexport LLM_PROVIDER='openai'[m
[32m+[m[32mexport LLM_MODEL='gpt-4'[m
[32m+[m
[32m+[m[32mstreamlit run main.py[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### Windows (PowerShell)[m
[32m+[m[32m```powershell[m
[32m+[m[32m$env:OPENAI_API_KEY='sk-your-api-key-here'[m
[32m+[m[32m$env:LLM_PROVIDER='openai'[m
[32m+[m[32m$env:LLM_MODEL='gpt-4'[m
[32m+[m
[32m+[m[32mstreamlit run main.py[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m</details>[m
[32m+[m
[32m+[m[32m### 3οΈβƒ£ μ›Ή λΈλΌμ°μ € μ ‘μ†[m
[32m+[m[32mλΈλΌμ°μ €κ°€ μλ™μΌλ΅ μ—΄λ¦¬κ±°λ‚, μλ™μΌλ΅ μ ‘μ†:[m
[32m+[m[32m```[m
[32m+[m[32mhttp://localhost:8501[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### 4οΈβƒ£ MCP μ„λ²„ ν…μ¤νΈ (μ„ νƒμ‚¬ν•­)[m
[32m+[m[32m```bash[m
[32m+[m[32mcd mcp-server[m
[32m+[m[32mpython client/main.py[m
[32m+[m[32m```[m
[32m+[m[32mπ“– μμ„Έν• λ‚΄μ©: [mcp-server/README.md](