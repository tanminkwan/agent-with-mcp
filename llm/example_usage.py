"""
LLM ëª¨ë“ˆ ì‚¬ìš© ì˜ˆì œ

ì´ íŒŒì¼ì€ ì¶”ìƒí™” ê³„ì¸µì„ ì‚¬ìš©í•˜ì—¬ Ollamaì™€ OpenAIë¥¼ 
ì–´ë–»ê²Œ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""
import os
from llm import LLMFactory


def example_ollama():
    """Ollama ì‚¬ìš© ì˜ˆì œ"""
    print("\n=== Ollama ì‚¬ìš© ì˜ˆì œ ===")
    
    # Ollama LLM ìƒì„±
    llm = LLMFactory.create(
        provider='ollama',
        model='llama2',
        temperature=0.7
    )
    
    print(f"ìƒì„±ëœ LLM: {llm.__class__.__name__}")
    print(f"ëª¨ë¸ëª…: {llm.get_model_name()}")
    print(f"ì„¤ì •: {llm.get_config()}")
    
    # LangChainê³¼ í•¨ê»˜ ì‚¬ìš©
    from langchain.schema import HumanMessage
    message = HumanMessage(content="ì•ˆë…•í•˜ì„¸ìš”!")
    response = llm([message])
    print(f"ì‘ë‹µ: {response.content}")


def example_openai():
    """OpenAI ì‚¬ìš© ì˜ˆì œ"""
    print("\n=== OpenAI ì‚¬ìš© ì˜ˆì œ ===")
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    if not os.getenv('OPENAI_API_KEY'):
        print("âš ï¸  OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("export OPENAI_API_KEY='your-api-key' ëª…ë ¹ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
        return
    
    # OpenAI LLM ìƒì„±
    llm = LLMFactory.create(
        provider='openai',
        model='gpt-4',
        temperature=0.7,
        max_tokens=100
    )
    
    print(f"ìƒì„±ëœ LLM: {llm.__class__.__name__}")
    print(f"ëª¨ë¸ëª…: {llm.get_model_name()}")
    print(f"ì„¤ì •: {llm.get_config()}")
    
    # LangChainê³¼ í•¨ê»˜ ì‚¬ìš©
    from langchain.schema import HumanMessage
    message = HumanMessage(content="ì•ˆë…•í•˜ì„¸ìš”!")
    response = llm([message])
    print(f"ì‘ë‹µ: {response.content}")


def example_with_agent():
    """Graph ê¸°ë°˜ Agent ì‚¬ìš© ì˜ˆì œ"""
    print("\n=== Graph ê¸°ë°˜ Agent ì‚¬ìš© ì˜ˆì œ ===")
    from agent.graphs.factory import create_from_env
    from agent.memory_agent import MemoryAgent

    graph_name = os.getenv('AGENT_GRAPH', 'purchase')
    print(f"ê·¸ë˜í”„ ì„ íƒ: {graph_name}")
    graph = create_from_env()
    agent = MemoryAgent(graph)

    response = agent.chat("ëˆ 12345 ì§€ë¶ˆí•´")
    print(f"\nAgent ì‘ë‹µ: {response}")


def show_available_providers():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì œê³µì ëª©ë¡ ì¶œë ¥"""
    print("\n=== ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì œê³µì ===")
    providers = LLMFactory.get_available_providers()
    for provider in providers:
        print(f"- {provider}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ LLM ì¶”ìƒí™” ê³„ì¸µ ì‚¬ìš© ì˜ˆì œ\n")
    print("SOLID ì›ì¹™ì„ ì ìš©í•œ LLM ëª¨ë“ˆ ë°ëª¨")
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì œê³µì í™•ì¸
    show_available_providers()
    
    # ê° ì œê³µìë³„ ì˜ˆì œ (ì£¼ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©)
    # example_ollama()
    # example_openai()
    
    # Agentì™€ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ì˜ˆì œ
    # example_with_agent()
    
    print("\nâœ… ì˜ˆì œ ì™„ë£Œ!")
    print("\nğŸ’¡ ì‚¬ìš© ë°©ë²•:")
    print("   AGENT_GRAPH=purchase python llm/example_usage.py")


if __name__ == "__main__":
    main()

