"""
Streamlit UI ëª¨ë“ˆ
í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•´ LLM ì œê³µìë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒ ê°€ëŠ¥

SOLID ì›ì¹™:
- ì˜ì¡´ì„± ì—­ì „ ì›ì¹™(DIP): êµ¬ì²´ í´ë˜ìŠ¤ê°€ ì•„ë‹Œ Factoryë¥¼ í†µí•œ ì¶”ìƒí™” ì‚¬ìš©
- ë‹¨ì¼ ì±…ì„ ì›ì¹™(SRP): UI í‘œì‹œë§Œ ë‹´ë‹¹, LLM ì„ íƒì€ Factoryì— ìœ„ì„
"""
import os
import streamlit as st
from agent.memory_agent import MemoryAgent
from llm import LLMFactory


def run():
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ LLM ì„¤ì • ì½ê¸° (Streamlit ì„¸ì…˜ì—ì„œë„ ë™ì‘)
    provider = os.getenv('LLM_PROVIDER', 'ollama')
    model = os.getenv('LLM_MODEL', 'gemma3n:e4b')
    
    # íƒ€ì´í‹€ì— í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ LLM í‘œì‹œ
    st.title(f"ğŸ¤– Multi-LLM Chatbot")
    st.caption(f"í˜„ì¬ ì‚¬ìš© ì¤‘: {provider.upper()} - {model}")
    
    # Agent ì´ˆê¸°í™” (ì„¸ì…˜ ìƒíƒœì— ì €ì¥)
    if "agent" not in st.session_state:
        try:
            llm = LLMFactory.create(provider=provider, model=model, temperature=0.7)
            st.session_state["agent"] = MemoryAgent(llm.as_langchain_model())
            st.session_state["llm_info"] = f"{llm.__class__.__name__} ({model})"
        except Exception as e:
            st.error(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            st.info("ğŸ’¡ Ollamaë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° 'ollama serve' ëª…ë ¹ìœ¼ë¡œ ì„œë²„ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            st.info("ğŸ’¡ OpenAIë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            st.stop()
    
    agent = st.session_state["agent"]
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    for msg in st.session_state["messages"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
    if user_input:
        st.session_state["messages"].append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)
        bot_response = agent.chat(user_input)
        st.session_state["messages"].append({"role": "assistant", "content": bot_response})
        with st.chat_message("assistant"):
            st.markdown(bot_response) 