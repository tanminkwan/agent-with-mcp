#!/usr/bin/env python3
import asyncio
import json
import os
from pathlib import Path
from fastmcp import Client
from typing import Any, Dict
from pydantic import create_model
from langchain.tools import StructuredTool
from langchain_openai import ChatOpenAI
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# utils ì¬ì‚¬ìš©ì„ ìœ„í•´ ê²½ë¡œ ì¶”ê°€
import sys
sys.path.append(str(Path(__file__).parent))
from utils import print_available_tools

# OPENAI í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¡œ ì œê³µí•˜ì„¸ìš” (ì˜ˆ: PowerShell â†’ $env:OPENAI_API_KEY = 'YOUR_API_KEY')

async def main() -> None:
    # openai_llm.pyì™€ ë™ì¼í•œ ë°©ì‹: ë³„ë„ì˜ .env ë¡œë“œ/í”„ë¡ì‹œ ì¡°ì‘ ì—†ì´ ì‚¬ìš©
    config_path = os.getenv("MCP_SERVERS_CONFIG", str(Path(__file__).parent.parent / "mcp_servers.json"))
    print(f"ğŸ—‚ï¸ ë©€í‹° ì„œë²„ ì„¤ì •: {config_path}")

    with open(config_path, "r", encoding="utf-8") as f:
        config = json.load(f)

    servers = list(config.get("mcpServers", {}).keys())
    print(f"ğŸ”— ëŒ€ìƒ ì„œë²„ë“¤: {', '.join(servers) if servers else '(ì—†ìŒ)'}")
    print()

    async with Client(config) as client:
        # ì „ì²´ ì„œë²„ íˆ´ ì¡°íšŒ(ì„ íƒì  ì¶œë ¥)
        await print_available_tools(client)

        # MCP íˆ´ â†’ LangChain StructuredTool ë³€í™˜ ìœ í‹¸
        def pyd_model_from_json_schema(name: str, schema: Dict[str, Any]):
            schema = schema or {"type": "object", "properties": {}}
            props = schema.get("properties", {})
            req = set(schema.get("required", []))
            def pytype(t: str):
                return {
                    "integer": int,
                    "number": float,
                    "boolean": bool,
                    "object": dict,
                    "array": list,
                }.get(t, str)
            fields = {k: (pytype(v.get("type", "string")), ... if k in req else None) for k, v in props.items()}
            return create_model(name, **fields) if fields else create_model(name)

        def make_langchain_tool(t: Any) -> StructuredTool:
            name = getattr(t, "name", None) or (t.get("name") if isinstance(t, dict) else None)
            desc = getattr(t, "description", "") or (t.get("description") if isinstance(t, dict) else "")
            params = getattr(t, "inputSchema", None) or (t.get("inputSchema") if isinstance(t, dict) else None)
            ArgsModel = pyd_model_from_json_schema(f"{name}_Args", params)

            async def _acall(**kwargs):
                res = await client.call_tool(name, kwargs)
                if hasattr(res, "content") and res.content:
                    texts = [c.text for c in res.content if hasattr(c, "text")]
                    return "\n".join(texts) if texts else str(res)
                return str(res)

            return StructuredTool.from_function(
                name=name,
                description=desc,
                args_schema=ArgsModel,
                coroutine=_acall,
            )

        # MCPì—ì„œ íˆ´ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ í›„ LangChain ë„êµ¬ë¡œ ë³€í™˜
        mcp_tools = await client.list_tools()
        lc_tools = [make_langchain_tool(t) for t in mcp_tools]

        # LangChain ì—ì´ì „íŠ¸ êµ¬ì„±: ëª¨ë¸ì´ ìì—°ì–´ë¡œ íˆ´ ì„ íƒ/í˜¸ì¶œ
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        prompt = ChatPromptTemplate.from_messages([
            ("system", "ë„ˆëŠ” ì œê³µëœ MCP íˆ´ ì¤‘ ì ì ˆí•œ ê²ƒì„ ì„ íƒí•´ í˜¸ì¶œí•œë‹¤. í•„ìš” ì—†ìœ¼ë©´ ì§ì ‘ ë‹µí•˜ë¼."),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        agent = create_tool_calling_agent(llm, lc_tools, prompt)
        executor = AgentExecutor(agent=agent, tools=lc_tools, verbose=True, handle_parsing_errors=True)

        # ëª¨ë¸ì´ ì§ì ‘ ë§í•˜ë„ë¡ ì…ë ¥ ì œê³µ
        user_query = "ëˆ 12345 ì§€ë¶ˆí•´"
        result = await executor.ainvoke({"input": user_query})
        print(result.get("output", "(ì¶œë ¥ ì—†ìŒ)"))

        print()
        print("âœ¨ ë©€í‹° ì„œë²„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    asyncio.run(main())


