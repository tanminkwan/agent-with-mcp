"""
ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•´ LLM ì œê³µìë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

í™˜ê²½ë³€ìˆ˜:
- LLM_PROVIDER: 'ollama' ë˜ëŠ” 'openai' (ê¸°ë³¸ê°’: ollama)
- LLM_MODEL: ëª¨ë¸ëª… (ê¸°ë³¸ê°’: gemma3n:e4b)
- OPENAI_API_KEY: OpenAI ì‚¬ìš© ì‹œ í•„ìš”

ì‚¬ìš© ì˜ˆì‹œ:
    python main.py
    LLM_PROVIDER=openai LLM_MODEL=gpt-4 OPENAI_API_KEY=sk-... python main.py
"""
import os
from dotenv import load_dotenv
from llm import LLMFactory
from agent.memory_agent import MemoryAgent
from ui.streamlit_ui import run

load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ

# í™˜ê²½ë³€ìˆ˜ì—ì„œ LLM ì„¤ì • ì½ê¸°
provider = os.getenv('LLM_PROVIDER', 'ollama')
model = os.getenv('LLM_MODEL', 'gemma3n:e4b')

# Factoryë¥¼ í†µí•´ LLM ìƒì„±
# SOLID ì›ì¹™ì˜ ì˜ì¡´ì„± ì—­ì „ ì›ì¹™(DIP) ì ìš©: êµ¬ì²´ í´ë˜ìŠ¤ê°€ ì•„ë‹Œ ì¶”ìƒí™”ì— ì˜ì¡´
llm = LLMFactory.create(
    provider=provider,
    model=model,
    temperature=0.7
)

# Agent ìƒì„±
# MemoryAgentëŠ” LangChain ëª¨ë¸ì„ í•„ìš”ë¡œ í•˜ë¯€ë¡œ as_langchain_model()ì„ ì‚¬ìš©
agent = MemoryAgent(llm.as_langchain_model())

print(f"ğŸ¤– ì‚¬ìš© ì¤‘ì¸ LLM: {llm.__class__.__name__} ({model})")

if __name__ == "__main__":
    run() 